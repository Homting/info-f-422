{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical foundations of Machine Learning INFO-F-422\n",
    "\n",
    "\n",
    "## TP 2 - Estimation\n",
    "\n",
    "#### *Yann-AÃ«l Le Borgne, Fabrizio Carcillo and Gianluca Bontempi*\n",
    "\n",
    "####  March 14, 2017\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic notions\n",
    "\n",
    "* Estimation: it is the procedure which allows to *estimate* a parameter of a distribution (expected value, variance, ...) from $N$ samples drawn from this distribution.\n",
    "* Typical estimators of the expected value and the variance are given by the sample mean\n",
    "$$\n",
    " \\hat{\\mu}=\\frac{1}{N}\\sum_{i=1}^N z_i\\\\\n",
    "$$\n",
    "and sample variance\n",
    "$$\n",
    "\\hat{\\sigma}^2= \\frac{1}{N-1}\\sum_{i=1}^N (z_i-\\hat{\\mu})^2,\n",
    "$$\n",
    "where $D_N=\\{z_1,\\ldots,z_n\\}$ is our sampleset.\n",
    "* An estimator $\\hat{\\boldsymbol{\\theta}}$ is a random variable itself, since it depends on a random sample $\\mathbf{D}_N$.\n",
    "* An estimator $\\hat{\\boldsymbol{\\theta}}$ of a parameter $\\theta$ is called unbiased if and only if\n",
    "\n",
    "\\begin{equation}\n",
    " {E}_{\\boldsymbol{D}_N}[\\hat{\\boldsymbol{\\theta}}]=\\theta.\n",
    "\\end{equation}\n",
    "\n",
    "If not, we define the *bias* as follows\n",
    "\n",
    "\\begin{equation}\n",
    "\\mbox{Bias}[\\hat{\\boldsymbol{\\theta}}]={E}_{\\boldsymbol{D}_N}[\\hat{\\boldsymbol{\\theta}}]-\\theta.\n",
    "\\end{equation}\n",
    "*  The variance of an estimator is defined as\n",
    "\\begin{equation}\n",
    " \\mbox{Var}[\\hat{\\boldsymbol{\\theta}}]={E}_{\\boldsymbol{D}_N}[(\\hat{\\boldsymbol{\\theta}}-E[\\hat{\\boldsymbol{\\theta}}])^2].\n",
    "\\end{equation}\n",
    "*  Bias and variance of $\\hat{\\mathbf{\\mu}}$:\n",
    "\\begin{equation}\n",
    " {E}_{\\boldsymbol{D}_N}[\\hat{\\boldsymbol{\\mu}}]=\\mu.\n",
    "\\end{equation}\n",
    "The estimator $\\hat{\\boldsymbol{\\mu}}$ is therefore unbiased and its variance is\n",
    "\\begin{equation}\n",
    "  \\mbox{Var}[\\hat{\\boldsymbol{\\mu}}]=\\frac{\\sigma^2}{N}.\n",
    "\\end{equation}\n",
    "where $\\mbox{Var}[{\\mathbf{z}}]=\\sigma^2$.\n",
    "\n",
    "*  Bias of $\\hat{\\boldsymbol{\\sigma}}^2$:\n",
    "\\begin{equation}\n",
    " E_{\\boldsymbol{D}_N}[\\hat{\\boldsymbol{\\sigma}}^2]=\\sigma^2.\n",
    "\\end{equation}\n",
    "The estimator $\\hat{\\boldsymbol{\\sigma}}^2$ is thus unbiased.\n",
    "\n",
    "*  The quality of an estimator $\\hat{\\boldsymbol{\\theta}}$ can be measured using the *mean square error*\n",
    "\n",
    "\\begin{equation}\n",
    " \\mbox{MSE}={E}_{\\boldsymbol{D}_N}[(\\theta - \\hat{\\boldsymbol{\\theta}})^2].\n",
    "\\end{equation}\n",
    "We can show that for all estimators $\\hat{\\boldsymbol{\\theta}}$\n",
    "\\begin{equation}\n",
    " \\mbox{MSE}=\\mbox{Var}[\\hat{\\boldsymbol{\\theta}}]+({E}[\\hat{\\boldsymbol{\\theta}}]-\\theta)^2.\n",
    "\\end{equation}\n",
    "is the sum of the variance and the squared bias.\n",
    "*  Let $\\hat{F}_z(x)=\\frac{1}{z}\\sum_{i=1}^z \\mathbb{1}_{x_i\\le t}$ be the empirical distribution function. We have\n",
    "\\begin{equation}\n",
    " {E}_{\\boldsymbol{D}_N}[\\hat{\\bf F}_z(x)]=F_z(x),\n",
    "\\end{equation}\n",
    "where $F_z(x)$ is the distribution function of the variable $\\boldsymbol{z}$.\n",
    "\n",
    "*  Let $N$ observations be drawn form a normal distribution with mean $\\mu$ and standard deviation $\\sigma$. The estimator $\\hat{\\boldsymbol{\\mu}}$ of the mean  follows a normal distribution with mean $\\mu$ and standard deviation $\\sigma/\\sqrt{N}$. It follows that a confidence interval for $\\mu$ is given by\n",
    "\n",
    "\\begin{equation}\n",
    " \\mbox{Prob}\\left\\{ \\hat{\\boldsymbol{\\mu}}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{N}} \\le \\mu\\le \\hat{\\boldsymbol{\\mu}}+z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{N}}\\right\\}=1-\\alpha,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha$ is directly related to the probability $P$ that the interval contains $\\mu$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical experiments \n",
    "\n",
    "The R programs are written in files with the extension '.R', which can be edited using text editors such as emacs, gedit, etc. The file can be loaded in the R terminal with the command\n",
    "\n",
    "```\n",
    "source(\"filename.R\")\n",
    "```\n",
    "\n",
    "The additional parameter *print.eval=T* forces all outputs of the scripts to be displayed on the screen: \n",
    "```\n",
    "source(\"filename.R\", print.eval=T)\n",
    "```\n",
    "\n",
    "You can directly change into the directory containing the scripts using the command \n",
    "```\n",
    "setwd(\"directory containing the scripts\")\n",
    "```\n",
    "The goal of this TP is to write script for the following exercises. \n",
    "\n",
    "You can use the scripts *cumdis.R, cumdis_2.R, sam_dis.R, sam_dis2.R, sam_dis_unif.R, mse_bv.R, combine.R* and *confidence.R* to help you with the exercises. The scripts are available on the homepage of the course: https://github.com/gbonte/gbcode/tree/master/inst/scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution function \n",
    "\n",
    "Write a script that displays the empirical cumulative distribution function of a distribution $\\mathcal{N}(1,2)$ with 100 observations. Use the functions *ecdf* and *rnorm*. See [cumdis.R](https://github.com/gbonte/gbcode/tree/master/inst/scripts/cumdis.R).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected value of the empirical distribution function\n",
    "\n",
    "Write a script which verifies the assertion ${E}_{\\mathbf{D}_N}[\\hat{\\bf F}_z(x)]=F_z(x)$ concerning the cumulative empirical distribution function. Modify the previous code in order to\n",
    "\n",
    "* generate $R$ samples of 100 observations\n",
    "* average the $R$ empirical cdfs\n",
    "* trace the distribution function of the sample mean and compare it with the theoretical distribution function.\n",
    "* observe the results for $R\\in \\{5,10,50,100\\}.$\n",
    "\n",
    "See [cumdis_2.R](https://github.com/gbonte/gbcode/tree/master/inst/scripts/cumdis_2.R)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator of the mean\n",
    "\n",
    "Write a script which returns 1000 estimations of the sample's mean using $N$ observations following a normal distribution $\\mathcal{N}(0,100)$. Une $N=50$, $N=75$ and $N=100$. Plot the histogram of these estimations and compare this with the theoretical distribution of the mean's estimator. \n",
    "\n",
    "Make use of the script [sam_dis.R](https://github.com/gbonte/gbcode/tree/master/inst/scripts/sam_dis.R) which allows to see in practice how the estimator $\\hat{\\boldsymbol{\\mu}}$ of the mean is distributed for a normal distribution of the data. \n",
    "\n",
    "Observe that it is unbiased and that its distribution is $\\mathcal{N}(\\mu, \\sigma^2/N)$ (have a look at the observed variances and at the shape of the histograms).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator of the variance\n",
    "\n",
    "Proceed equivalently except that here the estimator of the variance is considered. We want to verify that $\\frac{(N-1)\\hat{\\boldsymbol{\\sigma}}^2}{\\sigma^2}\\sim \\chi^2_{N-1}$. Use $N=10$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and variance\n",
    "\n",
    "Write a script which verifies the equation\n",
    "\n",
    "\\begin{equation}\n",
    " \\mbox{MSE}=\\mbox{Var}[\\hat{\\boldsymbol{\\theta}}]+({E}[\\hat{\\boldsymbol{\\theta}}]-\\theta)^2.\n",
    "\\end{equation}\n",
    "\n",
    "Take as an example the estimator of the mean of 10 observations following the distribution $\\mathcal{N}(0,100)$, by generating 10000 estimations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean of estimators\n",
    "\n",
    "The mean of unbiased estimators, having the same variance is itself unbiased but has a variance twice smaller than that of the estimators it has been derived from (see slide 30 in the file http://www.ulb.ac.be/di/map/gbonte/mod_stoch/nonlin.pdf). Write a script which illustrates this by\n",
    "\n",
    "* generating independently two distributions of the estimator of the mean for a uniform distribution assuming values between -10 and 10,\n",
    "* displaying the histograms of the two distributions and the combination of both and compute their variance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals\n",
    "\n",
    "Write a script which generates $N$ samples of the distribution $\\mathcal{N}(1,5)$, returns the percentage of values not falling into the $P\\%$ confidence interval. Test, using $P=95\\%$ with $N=100$ and $N=1000$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
